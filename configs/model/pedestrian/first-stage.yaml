# Model Configuration
_target_: src.models.composites.first_stage.pedestrian.Wrapper
_recursive_: False
monitor: val/loss
interval: step
compile: False
shift: ${shift}
scale: ${scale}

loss:
  _target_: src.models.composites.first_stage.pedestrian.Loss
  loss_pos_weight: 1
  loss_pos:
    _target_: src.modules.losses.MaskedMSELoss

  loss_inter_distance_weight: 1
  loss_inter_distance:
    _target_: src.modules.losses.InterDistanceLoss

  loss_norm_weight: 0
  loss_norm:
    _target_: src.modules.losses.MaskedNormLoss

backbone:
  _target_: src.models.composites.first_stage.pedestrian.Backbone
  dim_input: 128
  dim_latent: 32
  act:
    _target_: src.modules.torch_modules.GELU
    _partial_: True

  embed_entity:
    _target_: src.modules.entity_embeddings.EntityEmbeddingOrthogonal
    n_entiy_embeddings: ${num_entities}
    embedding_dim: 128
    max_norm: 1

  encoder:
    _target_: src.models.components.encoder.Encoder
    _partial_: True
    dim_input: ${model.backbone.dim_input}
    dim_latent: ${model.backbone.dim_latent}
    dim_head_cross: 16
    dim_head_latent: 16
    num_latents: 2
    num_head_cross: 4
    num_head_latent: 2
    num_block_attn: 1
    num_block_cross: 1
    qk_norm: True
    act: ${model.backbone.act}

  decoder:
    _target_: src.models.components.decoder.Decoder
    _partial_: True
    outputs:
      pos: 2
    dim_latent: ${model.backbone.encoder.dim_latent}
    dim_query: ${model.backbone.embed_entity.embedding_dim}
    dim_head_cross: 16
    dim_head_latent: 16
    num_head_cross: 4
    num_head_latent: 2
    num_block_cross: 0
    num_block_attn: 1
    dropout_query: 0.1
    dropout_latent: 0.0
    qk_norm: ${model.backbone.encoder.qk_norm}
    act: ${model.backbone.act}

ema:
  _target_: src.modules.ema.ExponentialMovingAverage
  _partial_: True
  decay: 0.999

optimizer:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 1e-3

scheduler:
  _target_: src.modules.schedulers.LinearWarmupCosineAnnealingLR
  _partial_: True
  warmup_epochs: 0
  max_epochs: ${trainer.max_epochs}
  min_lr: 1e-7
